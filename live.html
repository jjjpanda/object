<html>
  <head>
    <link rel="stylesheet" href="https://vjs.zencdn.net/7.0.0/video-js.css">
    <link rel="stylesheet" href="styles.css">
  </head>
  
  <body>
      <!-- Load TensorFlow.js. This is required to use coco-ssd model. -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.12.0"> </script>
    <!-- Load the coco-ssd model. -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2"> </script>
    <script src="https://vjs.zencdn.net/7.0.0/video.min.js"></script>

    <div>
        <video autoplay width=600 height=300 id = "webcam" class="fixPosition2"></video>
        <canvas
          id="bbox"
          width="600"
          height="300"
          class="fixPosition2"
        />
    </div>

    <div>
        <video width=600 height=300 id="example-video-dash" class="video-js vjs-default-skin fixPosition" controls> </video>  
    </div>

    <video width=600 height=300 id="example-video-hls" class="video-js vjs-default-skin fixPosition3" controls><source
      src="http://localhost:8080/feed/1/video.m3u8"
      type="application/x-mpegURL"> 
    </video>
    
    <script>
        var video = document.querySelector("#webcam");

        if (navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices.getUserMedia({ video: true })
            .then(function (stream) {
            video.srcObject = stream;
            })
            .catch(function (err0r) {
            console.log("Something went wrong!");
            });
        }

        var dashPlayer = videojs('example-video-dash');
        dashPlayer.src({ src: 'http://localhost:8080/feed/1/video.mpd', type: 'application/dash+xml'});
        dashPlayer.play();

        var hlsPlayer = videojs('example-video-hls');
        hlsPlayer.play();

        const vid = document.getElementById('example-video-dash_html5_api');

        const modelDetect = (m, v) => {
          m.detect(v).then(predictions => {
            if(predictions.length > 0) console.log('Predictions: ', predictions);
            const c = document.getElementById('bbox');
            var ctx = c.getContext("2d");
            ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);
            // Font options.
            const font = "16px sans-serif";
            ctx.font = font;
            ctx.textBaseline = "top";
            predictions.forEach(prediction => {
                const x = prediction.bbox[0];
                const y = prediction.bbox[1];
                const width = prediction.bbox[2];
                const height = prediction.bbox[3];
                // Draw the bounding box.
                ctx.strokeStyle = "#00FFFF";
                ctx.lineWidth = 4;
                ctx.strokeRect(x, y, width, height);
                // Draw the label background.
                ctx.fillStyle = "#00FFFF";
                const textWidth = ctx.measureText(prediction.class).width;
                const textHeight = parseInt(font, 10); // base 10
                ctx.fillRect(x, y, textWidth + 4, textHeight + 4);
            });
          }).catch(e => console.log(e)).finally(() => {
            requestAnimationFrame(() => {
              modelDetect(m, v)
            })
          });
        }

        vid.addEventListener('loadeddata', function() {
            cocoSsd.load().then(model => {
              modelDetect(model, vid) 
            });
        }, false);
        
    </script>
  </body>
</html>